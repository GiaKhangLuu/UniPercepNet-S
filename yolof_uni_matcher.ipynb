{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19467c73-1060-4728-a177-c307d8b13fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "import matplotlib.pyplot as plt\n",
    "#from google.colab.patches import cv2_imshow\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fa314ca-6e55-46a4-a8d5-e85f09191cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/15 00:01:26 d2.data.datasets.coco]: \u001b[0m./kitti/training_coco/train_temp.json contains 41322 annotations, but only 3 of them match to images in the file.\n",
      "\u001b[32m[03/15 00:01:26 d2.data.datasets.coco]: \u001b[0mLoaded 1 images in COCO format from ./kitti/training_coco/train_temp.json\n"
     ]
    }
   ],
   "source": [
    "dataset = 'kitti'\n",
    "annot_dir = './kitti/training_coco'\n",
    "imgs_dir = './kitti/training_voc/VOC2012/JPEGImages'\n",
    "\n",
    "for split in ['train', 'val']: \n",
    "    if split == 'train':\n",
    "        annot_path = os.path.join(annot_dir, f'{split}_temp.json')\n",
    "    else:\n",
    "        annot_path = os.path.join(annot_dir, f'{split}.json')\n",
    "    d_name = dataset + f'_{split}'\n",
    "    register_coco_instances(d_name, {}, annot_path, imgs_dir)\n",
    "\n",
    "# Load dataset\n",
    "dataset_dicts = DatasetCatalog.get('kitti_train')\n",
    "metadata = MetadataCatalog.get('kitti_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bc9376f-bc41-4a75-8161-5599f29924f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "class Args(argparse.Namespace):\n",
    "    config_file='khang_net/configs/yolof/yolof_resnet_50_1x.py'\n",
    "    eval_only=False\n",
    "    num_gpus=1\n",
    "    num_machines=1\n",
    "    resume=False\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01c6b9f8-9a1e-4e56-a80e-eae2b02dc3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.model_zoo import get_config\n",
    "from detectron2.config import LazyConfig\n",
    "from detectron2.config.instantiate import instantiate\n",
    "\n",
    "\n",
    "cfg = LazyConfig.load(\"khang_net/configs/yolof/yolof_resnet_50_1x.py\")\n",
    "cfg.train.device = 'mps'\n",
    "cfg.dataloader.evaluator.dataset_name = 'kitti_val'\n",
    "cfg.dataloader.train.dataset.names = 'kitti_train'\n",
    "cfg.dataloader.train.total_batch_size = 1\n",
    "cfg.optimizer.lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e77d36f3-f003-439c-a220-eeb6f7e5f7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/14 23:59:07 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
      "\u001b[32m[03/14 23:59:07 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
      "\u001b[32m[03/14 23:59:08 detectron2]: \u001b[0mEnvironment info:\n",
      "-------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "sys.platform                     darwin\n",
      "Python                           3.9.18 | packaged by conda-forge | (main, Dec 23 2023, 16:35:41) [Clang 16.0.6 ]\n",
      "numpy                            1.26.4\n",
      "detectron2                       0.6 @/Users/giakhang/dev/work/sand_box/hope_to_public_net/detectron2/detectron2\n",
      "detectron2._C                    not built correctly: dlopen(/Users/giakhang/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/_C.cpython-39-darwin.so, 0x0002): tried: '/opt/homebrew/opt/libomp/lib/_C.cpython-39-darwin.so' (no such file), '/_C.cpython-39-darwin.so' (no such file), '/Users/giakhang/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/_C.cpython-39-darwin.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64')), '/System/Volumes/Preboot/Cryptexes/OS/Users/giakhang/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/_C.cpython-39-darwin.so' (no such file), '/Users/giakhang/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/_C.cpython-39-darwin.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64'))\n",
      "Compiler ($CXX)                  Apple clang version 14.0.3 (clang-1403.0.22.14.1)\n",
      "DETECTRON2_ENV_MODULE            <not set>\n",
      "PyTorch                          2.2.1 @/Users/giakhang/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch\n",
      "PyTorch debug build              False\n",
      "torch._C._GLIBCXX_USE_CXX11_ABI  False\n",
      "GPU available                    No: torch.cuda.is_available() == False\n",
      "Pillow                           10.2.0\n",
      "torchvision                      0.17.1 @/Users/giakhang/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torchvision\n",
      "fvcore                           0.1.5.post20221221\n",
      "iopath                           0.1.9\n",
      "cv2                              4.9.0\n",
      "-------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PyTorch built with:\n",
      "  - GCC 4.2\n",
      "  - C++ Version: 201703\n",
      "  - clang 13.1.6\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: NO AVX\n",
      "  - Build settings: BLAS_INFO=accelerate, BUILD_TYPE=Release, CXX_COMPILER=/Applications/Xcode_13.3.1.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang++, CXX_FLAGS= -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_PYTORCH_METAL_EXPORT -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DUSE_COREML_DELEGATE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=braced-scalar-init -Werror=range-loop-construct -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wvla-extension -Wsuggest-override -Wnewline-eof -Winconsistent-missing-override -Winconsistent-missing-destructor-override -Wno-pass-failed -Wno-error=pedantic -Wno-error=old-style-cast -Wno-error=inconsistent-missing-override -Wno-error=inconsistent-missing-destructor-override -Wconstant-conversion -Wno-invalid-partial-specialization -Wno-missing-braces -Qunused-arguments -fcolor-diagnostics -faligned-new -Wno-unused-but-set-variable -fno-math-errno -fno-trapping-math -Werror=format -DUSE_MPS -Wno-unused-private-field -Wno-missing-braces, LAPACK_INFO=accelerate, TORCH_VERSION=2.2.1, USE_CUDA=0, USE_CUDNN=OFF, USE_EIGEN_FOR_BLAS=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=OFF, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=ON, USE_OPENMP=OFF, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \n",
      "\n",
      "\u001b[32m[03/14 23:59:08 detectron2]: \u001b[0mEnvironment info:\n",
      "-------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "sys.platform                     darwin\n",
      "Python                           3.9.18 | packaged by conda-forge | (main, Dec 23 2023, 16:35:41) [Clang 16.0.6 ]\n",
      "numpy                            1.26.4\n",
      "detectron2                       0.6 @/Users/giakhang/dev/work/sand_box/hope_to_public_net/detectron2/detectron2\n",
      "detectron2._C                    not built correctly: dlopen(/Users/giakhang/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/_C.cpython-39-darwin.so, 0x0002): tried: '/opt/homebrew/opt/libomp/lib/_C.cpython-39-darwin.so' (no such file), '/_C.cpython-39-darwin.so' (no such file), '/Users/giakhang/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/_C.cpython-39-darwin.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64')), '/System/Volumes/Preboot/Cryptexes/OS/Users/giakhang/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/_C.cpython-39-darwin.so' (no such file), '/Users/giakhang/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/_C.cpython-39-darwin.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64'))\n",
      "Compiler ($CXX)                  Apple clang version 14.0.3 (clang-1403.0.22.14.1)\n",
      "DETECTRON2_ENV_MODULE            <not set>\n",
      "PyTorch                          2.2.1 @/Users/giakhang/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch\n",
      "PyTorch debug build              False\n",
      "torch._C._GLIBCXX_USE_CXX11_ABI  False\n",
      "GPU available                    No: torch.cuda.is_available() == False\n",
      "Pillow                           10.2.0\n",
      "torchvision                      0.17.1 @/Users/giakhang/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torchvision\n",
      "fvcore                           0.1.5.post20221221\n",
      "iopath                           0.1.9\n",
      "cv2                              4.9.0\n",
      "-------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PyTorch built with:\n",
      "  - GCC 4.2\n",
      "  - C++ Version: 201703\n",
      "  - clang 13.1.6\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: NO AVX\n",
      "  - Build settings: BLAS_INFO=accelerate, BUILD_TYPE=Release, CXX_COMPILER=/Applications/Xcode_13.3.1.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang++, CXX_FLAGS= -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_PYTORCH_METAL_EXPORT -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DUSE_COREML_DELEGATE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=braced-scalar-init -Werror=range-loop-construct -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wvla-extension -Wsuggest-override -Wnewline-eof -Winconsistent-missing-override -Winconsistent-missing-destructor-override -Wno-pass-failed -Wno-error=pedantic -Wno-error=old-style-cast -Wno-error=inconsistent-missing-override -Wno-error=inconsistent-missing-destructor-override -Wconstant-conversion -Wno-invalid-partial-specialization -Wno-missing-braces -Qunused-arguments -fcolor-diagnostics -faligned-new -Wno-unused-but-set-variable -fno-math-errno -fno-trapping-math -Werror=format -DUSE_MPS -Wno-unused-private-field -Wno-missing-braces, LAPACK_INFO=accelerate, TORCH_VERSION=2.2.1, USE_CUDA=0, USE_CUDNN=OFF, USE_EIGEN_FOR_BLAS=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=OFF, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=ON, USE_OPENMP=OFF, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \n",
      "\n",
      "\u001b[32m[03/14 23:59:08 detectron2]: \u001b[0mCommand line arguments: Args()\n",
      "\u001b[32m[03/14 23:59:08 detectron2]: \u001b[0mCommand line arguments: Args()\n",
      "\u001b[32m[03/14 23:59:08 detectron2]: \u001b[0mContents of args.config_file=khang_net/configs/yolof/yolof_resnet_50_1x.py:\n",
      "\u001b[38;5;204mfrom\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mdetectron2\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mmodel_zoo\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mconfigs\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mcommon\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mtrain\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204mimport\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mtrain\u001b[39m\n",
      "\n",
      "\u001b[38;5;204mfrom\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mkhang_net\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mconfigs\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15myolof\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mbase_yolof\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204mimport\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mmodel\u001b[39m\n",
      "\u001b[38;5;204mfrom\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mkhang_net\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mconfigs\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15myolof\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15moptim\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204mimport\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mYOLOF_SGD\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;81mas\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15moptimizer\u001b[39m\n",
      "\u001b[38;5;204mfrom\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mkhang_net\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mconfigs\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15myolof\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mcoco_schedule\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204mimport\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mlr_multiplier_1x\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;81mas\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mlr_multiplier\u001b[39m\n",
      "\u001b[38;5;204mfrom\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mkhang_net\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mconfigs\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15myolof\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mcoco_dataloader\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204mimport\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mdataloader\u001b[39m\n",
      "\n",
      "\u001b[38;5;15mdataloader\u001b[39m\u001b[38;5;204m.\u001b[39m\u001b[38;5;15mtrain\u001b[39m\u001b[38;5;204m.\u001b[39m\u001b[38;5;15mmapper\u001b[39m\u001b[38;5;204m.\u001b[39m\u001b[38;5;15muse_instance_mask\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204m=\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;81mFalse\u001b[39m\n",
      "\n",
      "\u001b[38;5;15mmodel\u001b[39m\u001b[38;5;204m.\u001b[39m\u001b[38;5;15mbackbone\u001b[39m\u001b[38;5;204m.\u001b[39m\u001b[38;5;15mfreeze_at\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204m=\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;141m2\u001b[39m\n",
      "\n",
      "\u001b[38;5;15mtrain\u001b[39m\u001b[38;5;15m[\u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;186minit_checkpoint\u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;15m]\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204m=\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
      "\u001b[38;5;15mtrain\u001b[39m\u001b[38;5;15m[\u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;186mmax_iter\u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;15m]\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204m=\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;141m22500\u001b[39m\n",
      "\n",
      "\u001b[32m[03/14 23:59:08 detectron2]: \u001b[0mContents of args.config_file=khang_net/configs/yolof/yolof_resnet_50_1x.py:\n",
      "\u001b[38;5;204mfrom\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mdetectron2\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mmodel_zoo\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mconfigs\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mcommon\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mtrain\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204mimport\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mtrain\u001b[39m\n",
      "\n",
      "\u001b[38;5;204mfrom\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mkhang_net\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mconfigs\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15myolof\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mbase_yolof\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204mimport\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mmodel\u001b[39m\n",
      "\u001b[38;5;204mfrom\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mkhang_net\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mconfigs\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15myolof\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15moptim\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204mimport\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mYOLOF_SGD\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;81mas\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15moptimizer\u001b[39m\n",
      "\u001b[38;5;204mfrom\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mkhang_net\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mconfigs\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15myolof\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mcoco_schedule\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204mimport\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mlr_multiplier_1x\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;81mas\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mlr_multiplier\u001b[39m\n",
      "\u001b[38;5;204mfrom\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mkhang_net\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mconfigs\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15myolof\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mcoco_dataloader\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204mimport\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mdataloader\u001b[39m\n",
      "\n",
      "\u001b[38;5;15mdataloader\u001b[39m\u001b[38;5;204m.\u001b[39m\u001b[38;5;15mtrain\u001b[39m\u001b[38;5;204m.\u001b[39m\u001b[38;5;15mmapper\u001b[39m\u001b[38;5;204m.\u001b[39m\u001b[38;5;15muse_instance_mask\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204m=\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;81mFalse\u001b[39m\n",
      "\n",
      "\u001b[38;5;15mmodel\u001b[39m\u001b[38;5;204m.\u001b[39m\u001b[38;5;15mbackbone\u001b[39m\u001b[38;5;204m.\u001b[39m\u001b[38;5;15mfreeze_at\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204m=\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;141m2\u001b[39m\n",
      "\n",
      "\u001b[38;5;15mtrain\u001b[39m\u001b[38;5;15m[\u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;186minit_checkpoint\u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;15m]\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204m=\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
      "\u001b[38;5;15mtrain\u001b[39m\u001b[38;5;15m[\u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;186mmax_iter\u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;15m]\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204m=\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;141m22500\u001b[39m\n",
      "\n",
      "\u001b[32m[03/14 23:59:08 detectron2]: \u001b[0mFull config saved to ./output/config.yaml\n",
      "\u001b[32m[03/14 23:59:08 detectron2]: \u001b[0mFull config saved to ./output/config.yaml\n",
      "\u001b[32m[03/14 23:59:08 d2.utils.env]: \u001b[0mUsing a generated random seed 8445293\n",
      "\u001b[32m[03/14 23:59:08 d2.utils.env]: \u001b[0mUsing a generated random seed 8445293\n"
     ]
    }
   ],
   "source": [
    "from detectron2.engine import default_setup\n",
    "\n",
    "default_setup(cfg, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "670b08af-6b2f-4a48-99b0-43085ea0252d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file_name': './kitti/training_voc/VOC2012/JPEGImages/004914.png',\n",
       "  'height': 375,\n",
       "  'width': 1242,\n",
       "  'image_id': '004914',\n",
       "  'annotations': [{'iscrowd': 0,\n",
       "    'bbox': [586, 179, 17, 14],\n",
       "    'category_id': 7,\n",
       "    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n",
       "   {'iscrowd': 0,\n",
       "    'bbox': [490, 179, 30, 22],\n",
       "    'category_id': 7,\n",
       "    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n",
       "   {'iscrowd': 0,\n",
       "    'bbox': [524, 173, 57, 18],\n",
       "    'category_id': 1,\n",
       "    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "066c6602-1afd-4ee8-a8f7-af52d32c5b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/14 23:59:11 detectron2]: \u001b[0mModel:\n",
      "YOLOF(\n",
      "  (backbone): ResNet(\n",
      "    (stem): BasicStem(\n",
      "      (conv1): Conv2d(\n",
      "        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (res2): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res3): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (3): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res4): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (3): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (4): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (5): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res5): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (encoder): DilatedEncoder(\n",
      "    (lateral_conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (lateral_norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fpn_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (dilated_encoder_blocks): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Sequential(\n",
      "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): Sequential(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv3): Sequential(\n",
      "          (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Sequential(\n",
      "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): Sequential(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv3): Sequential(\n",
      "          (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Sequential(\n",
      "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): Sequential(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv3): Sequential(\n",
      "          (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Sequential(\n",
      "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): Sequential(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8))\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv3): Sequential(\n",
      "          (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): YOLOFDecoder(\n",
      "    (cls_subnet): Sequential(\n",
      "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "    (bbox_subnet): Sequential(\n",
      "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (8): ReLU(inplace=True)\n",
      "      (9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (10): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (11): ReLU(inplace=True)\n",
      "    )\n",
      "    (cls_score): Conv2d(512, 400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bbox_pred): Conv2d(512, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (object_pred): Conv2d(512, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (anchor_generator): YOLOFAnchorGenerator(\n",
      "    (cell_anchors): BufferList()\n",
      "  )\n",
      "  (anchor_matcher): UniformMatcher()\n",
      ")\n",
      "\u001b[32m[03/14 23:59:11 detectron2]: \u001b[0mModel:\n",
      "YOLOF(\n",
      "  (backbone): ResNet(\n",
      "    (stem): BasicStem(\n",
      "      (conv1): Conv2d(\n",
      "        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (res2): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res3): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (3): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res4): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (3): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (4): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (5): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res5): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (encoder): DilatedEncoder(\n",
      "    (lateral_conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (lateral_norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fpn_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (dilated_encoder_blocks): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Sequential(\n",
      "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): Sequential(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv3): Sequential(\n",
      "          (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Sequential(\n",
      "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): Sequential(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv3): Sequential(\n",
      "          (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Sequential(\n",
      "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): Sequential(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv3): Sequential(\n",
      "          (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Sequential(\n",
      "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): Sequential(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8))\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv3): Sequential(\n",
      "          (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): YOLOFDecoder(\n",
      "    (cls_subnet): Sequential(\n",
      "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "    (bbox_subnet): Sequential(\n",
      "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (8): ReLU(inplace=True)\n",
      "      (9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (10): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (11): ReLU(inplace=True)\n",
      "    )\n",
      "    (cls_score): Conv2d(512, 400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bbox_pred): Conv2d(512, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (object_pred): Conv2d(512, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (anchor_generator): YOLOFAnchorGenerator(\n",
      "    (cell_anchors): BufferList()\n",
      "  )\n",
      "  (anchor_matcher): UniformMatcher()\n",
      ")\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/14 23:59:11 d2.data.datasets.coco]: \u001b[0m./kitti/training_coco/train_temp.json contains 41322 annotations, but only 3 of them match to images in the file.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/14 23:59:11 d2.data.datasets.coco]: \u001b[0m./kitti/training_coco/train_temp.json contains 41322 annotations, but only 3 of them match to images in the file.\n",
      "\u001b[32m[03/14 23:59:11 d2.data.datasets.coco]: \u001b[0mLoaded 1 images in COCO format from ./kitti/training_coco/train_temp.json\n",
      "\u001b[32m[03/14 23:59:11 d2.data.datasets.coco]: \u001b[0mLoaded 1 images in COCO format from ./kitti/training_coco/train_temp.json\n",
      "\u001b[32m[03/14 23:59:11 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 1 images left.\n",
      "\u001b[32m[03/14 23:59:11 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 1 images left.\n",
      "\u001b[32m[03/14 23:59:11 d2.data.build]: \u001b[0mDistribution of instances among all 9 categories:\n",
      "\u001b[36m|   category    | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:-------------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|    Cyclist    | 0            |  DontCare  | 1            |    Misc    | 0            |\n",
      "| Person_sitt.. | 0            |    Tram    | 0            |   Truck    | 0            |\n",
      "|      Van      | 0            |    car     | 2            |   person   | 0            |\n",
      "|               |              |            |              |            |              |\n",
      "|     total     | 3            |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/14 23:59:11 d2.data.build]: \u001b[0mDistribution of instances among all 9 categories:\n",
      "\u001b[36m|   category    | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:-------------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|    Cyclist    | 0            |  DontCare  | 1            |    Misc    | 0            |\n",
      "| Person_sitt.. | 0            |    Tram    | 0            |   Truck    | 0            |\n",
      "|      Van      | 0            |    car     | 2            |   person   | 0            |\n",
      "|               |              |            |              |            |              |\n",
      "|     total     | 3            |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/14 23:59:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=[800], max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/14 23:59:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=[800], max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/14 23:59:11 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[03/14 23:59:11 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[03/14 23:59:11 d2.data.common]: \u001b[0mSerializing 1 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/14 23:59:11 d2.data.common]: \u001b[0mSerializing 1 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/14 23:59:11 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[32m[03/14 23:59:11 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[32m[03/14 23:59:11 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=1\n",
      "\u001b[32m[03/14 23:59:11 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=1\n",
      "\u001b[32m[03/14 23:59:11 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...\n",
      "\u001b[32m[03/14 23:59:11 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...\n",
      "\u001b[32m[03/14 23:59:11 fvcore.common.checkpoint]: \u001b[0m[Checkpointer] Loading from /Users/giakhang/.torch/iopath_cache/detectron2/ImageNetPretrained/MSRA/R-50.pkl ...\n",
      "\u001b[32m[03/14 23:59:11 d2.checkpoint.c2_model_loading]: \u001b[0mRenaming Caffe2 weights ......\n",
      "\u001b[32m[03/14 23:59:11 d2.checkpoint.c2_model_loading]: \u001b[0mRenaming Caffe2 weights ......\n",
      "\u001b[32m[03/14 23:59:11 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with submodule backbone - Total num: 54\n",
      "\u001b[32m[03/14 23:59:11 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with submodule backbone - Total num: 54\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/14 23:59:11 fvcore.common.checkpoint]: \u001b[0mSome model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34manchor_generator.cell_anchors.0\u001b[0m\n",
      "\u001b[34mdecoder.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mdecoder.bbox_subnet.0.{bias, weight}\u001b[0m\n",
      "\u001b[34mdecoder.bbox_subnet.1.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "\u001b[34mdecoder.bbox_subnet.10.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "\u001b[34mdecoder.bbox_subnet.3.{bias, weight}\u001b[0m\n",
      "\u001b[34mdecoder.bbox_subnet.4.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "\u001b[34mdecoder.bbox_subnet.6.{bias, weight}\u001b[0m\n",
      "\u001b[34mdecoder.bbox_subnet.7.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "\u001b[34mdecoder.bbox_subnet.9.{bias, weight}\u001b[0m\n",
      "\u001b[34mdecoder.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mdecoder.cls_subnet.0.{bias, weight}\u001b[0m\n",
      "\u001b[34mdecoder.cls_subnet.1.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "\u001b[34mdecoder.cls_subnet.3.{bias, weight}\u001b[0m\n",
      "\u001b[34mdecoder.cls_subnet.4.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "\u001b[34mdecoder.object_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mencoder.dilated_encoder_blocks.0.conv1.0.{bias, weight}\u001b[0m\n",
      "\u001b[34mencoder.dilated_encoder_blocks.0.conv1.1.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "\u001b[34mencoder.dilated_encoder_blocks.0.conv2.0.{bias, weight}\u001b[0m\n",
      "\u001b[34mencoder.dilated_encoder_blocks.0.conv2.1.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "\u001b[34mencoder.dilated_encoder_blocks.0.conv3.0.{bias, weight}\u001b[0m\n",
      "\u001b[34mencoder.dilated_encoder_blocks.0.conv3.1.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "\u001b[34mencoder.dilated_encoder_blocks.1.conv1.0.{bias, weight}\u001b[0m\n",
      "\u001b[34mencoder.dilated_encoder_blocks.1.conv1.1.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "\u001b[34mencoder.dilated_encoder_blocks.1.conv2.0.{bias, weight}\u001b[0m\n",
      "\u001b[34mencoder.dilated_encoder_blocks.1.conv2.1.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "\u001b[34mencoder.dilated_encoder_blocks.1.conv3.0.{bias, weight}\u001b[0m\n",
      "\u001b[34mencoder.dilated_encoder_blocks.1.conv3.1.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "\u001b[34mencoder.dilated_encoder_blocks.2.conv1.0.{bias, weight}\u001b[0m\n",
      "\u001b[34mencoder.dilated_encoder_blocks.2.conv1.1.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "\u001b[34mencoder.dilated_encoder_blocks.2.conv2.0.{bias, weight}\u001b[0m\n",
      "\u001b[34mencoder.dilated_encoder_blocks.2.conv2.1.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "\u001b[34mencoder.dilated_encoder_blocks.2.conv3.0.{bias, weight}\u001b[0m\n",
      "\u001b[34mencoder.dilated_encoder_blocks.2.conv3.1.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "\u001b[34mencoder.dilated_encoder_blocks.3.conv1.0.{bias, weight}\u001b[0m\n",
      "\u001b[34mencoder.dilated_encoder_blocks.3.conv1.1.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "\u001b[34mencoder.dilated_encoder_blocks.3.conv2.0.{bias, weight}\u001b[0m\n",
      "\u001b[34mencoder.dilated_encoder_blocks.3.conv2.1.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "\u001b[34mencoder.dilated_encoder_blocks.3.conv3.0.{bias, weight}\u001b[0m\n",
      "\u001b[34mencoder.dilated_encoder_blocks.3.conv3.1.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "\u001b[34mencoder.fpn_conv.{bias, weight}\u001b[0m\n",
      "\u001b[34mencoder.fpn_norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "\u001b[34mencoder.lateral_conv.{bias, weight}\u001b[0m\n",
      "\u001b[34mencoder.lateral_norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/14 23:59:11 fvcore.common.checkpoint]: \u001b[0mThe checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mfc1000.{bias, weight}\u001b[0m\n",
      "  \u001b[35mstem.conv1.bias\u001b[0m\n",
      "\u001b[32m[03/14 23:59:11 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/14 23:59:11 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/14 23:59:14 d2.engine.hooks]: \u001b[0mTotal training time: 0:00:02 (0:00:00 on hooks)\n",
      "\u001b[32m[03/14 23:59:14 d2.engine.hooks]: \u001b[0mTotal training time: 0:00:02 (0:00:00 on hooks)\n",
      "\u001b[32m[03/14 23:59:14 d2.utils.events]: \u001b[0m iter: 0       lr: N/A  \n",
      "\u001b[32m[03/14 23:59:14 d2.utils.events]: \u001b[0m iter: 0       lr: N/A  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazyconfig_train_net\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m do_train\n\u001b[0;32m----> 3\u001b[0m \u001b[43mdo_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/work/sand_box/hope_to_public_net/detectron2/tools/lazyconfig_train_net.py:108\u001b[0m, in \u001b[0;36mdo_train\u001b[0;34m(args, cfg)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m     start_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 108\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/engine/train_loop.py:155\u001b[0m, in \u001b[0;36mTrainerBase.train\u001b[0;34m(self, start_iter, max_iter)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_iter, max_iter):\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbefore_step()\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter_step()\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# self.iter == max_iter can be used by `after_train` to\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# tell whether the training successfully finished or failed\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# due to exceptions.\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/engine/train_loop.py:310\u001b[0m, in \u001b[0;36mSimpleTrainer.run_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    307\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;124;03mIf you want to do something with the losses, you can wrap the model.\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m loss_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loss_dict, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    312\u001b[0m     losses \u001b[38;5;241m=\u001b[39m loss_dict\n",
      "File \u001b[0;32m~/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/work/sand_box/hope_to_public_net/khang_net/modeling/meta_arch/yolof.py:127\u001b[0m, in \u001b[0;36mYOLOF.forward\u001b[0;34m(self, batched_inputs)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m    batched_inputs: a list, batched outputs of :class:`DatasetMapper` .\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m    in :doc:`/tutorials/models`.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    126\u001b[0m images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_image(batched_inputs)\n\u001b[0;32m--> 127\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# Temporarily hard code this feature out\u001b[39;00m\n\u001b[1;32m    129\u001b[0m features \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mres5\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/modeling/backbone/resnet.py:449\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    447\u001b[0m     outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstem\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, stage \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstage_names, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstages):\n\u001b[0;32m--> 449\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mstage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_out_features:\n\u001b[1;32m    451\u001b[0m         outputs[name] \u001b[38;5;241m=\u001b[39m x\n",
      "File \u001b[0;32m~/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/modeling/backbone/resnet.py:201\u001b[0m, in \u001b[0;36mBottleneckBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    198\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(out)\n\u001b[1;32m    199\u001b[0m out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu_(out)\n\u001b[0;32m--> 201\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshortcut \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    204\u001b[0m     shortcut \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshortcut(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/layers/wrappers.py:127\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m    122\u001b[0m                 \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/12013\u001b[39;00m\n\u001b[1;32m    123\u001b[0m                 \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    124\u001b[0m                     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mSyncBatchNorm\n\u001b[1;32m    125\u001b[0m                 ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSyncBatchNorm does not support empty inputs!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 127\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    131\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tools.lazyconfig_train_net import do_train\n",
    "\n",
    "do_train(args, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9f680e-3e13-4772-9ab1-c8135924f685",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f379b220-a01b-49aa-aa3f-aaa5e551187d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de15b13-cb74-412c-af0b-967ba899a4fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a51f405-bc38-4bf0-b6dd-63b905518e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e6a23f6-eb5f-4310-bfce-3229e26f280c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/15 00:01:56 d2.data.datasets.coco]: \u001b[0m./kitti/training_coco/train_temp.json contains 41322 annotations, but only 3 of them match to images in the file.\n",
      "\u001b[32m[03/15 00:01:56 d2.data.datasets.coco]: \u001b[0mLoaded 1 images in COCO format from ./kitti/training_coco/train_temp.json\n",
      "\u001b[32m[03/15 00:01:56 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 1 images left.\n",
      "\u001b[32m[03/15 00:01:56 d2.data.build]: \u001b[0mDistribution of instances among all 9 categories:\n",
      "\u001b[36m|   category    | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:-------------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|    Cyclist    | 0            |  DontCare  | 1            |    Misc    | 0            |\n",
      "| Person_sitt.. | 0            |    Tram    | 0            |   Truck    | 0            |\n",
      "|      Van      | 0            |    car     | 2            |   person   | 0            |\n",
      "|               |              |            |              |            |              |\n",
      "|     total     | 3            |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/15 00:01:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=[800], max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/15 00:01:56 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[03/15 00:01:56 d2.data.common]: \u001b[0mSerializing 1 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/15 00:01:56 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[32m[03/15 00:01:56 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=1\n"
     ]
    }
   ],
   "source": [
    "model = instantiate(cfg.model)\n",
    "dataloader = instantiate(cfg.dataloader.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3dd78c5-c94a-40a4-9fa8-703ff795fc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f317212-44ae-4dda-a11c-48423b712200",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = batch[0]['image']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609578ce-1e97-41d4-92df-60c20f691d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.ascontiguousarray(img.permute(1, 2, 0), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465e04b0-3d23-4b5f-aaa5-e300eddcfd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3a9ba9-31b5-43f5-91e1-8373b37c2306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "gt_boxes = batch[0]['instances'].gt_boxes.tensor.to(torch.int64).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0785f63c-4c3f-4f4b-8999-2a583ae41aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d3b74a-7823-4f72-a9a8-cf3bca08d311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "for gt_box in gt_boxes:\n",
    "    img = cv2.rectangle(img, (gt_box[0], gt_box[1]),\n",
    "                        (gt_box[2], gt_box[3]),\n",
    "                        (0, 0, 255), 2, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5215d9e9-00f7-4810-a8b0-2a3b0ec10d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 12))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c54a92-9bdc-413e-948c-47cd97d56c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "h, w = 13, 42\n",
    "channels = 3\n",
    "features = torch.rand((batch_size, channels, h, w))\n",
    "features = [features]\n",
    "\n",
    "anchors = model.anchor_generator(features)\n",
    "pred_anchor_deltas = [torch.zeros((batch_size, h * w * 5, 4))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36217fd5-75b4-40c8-a367-83024ba35702",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = model.get_ground_truth(anchors, pred_anchor_deltas, [batch[0]['instances']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b6c1c2-7681-4d06-8bdc-e8dab0170ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28108ed-bb06-4128-83bf-248fe6a508ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_boxes = anchors[0][0].tensor[indices[0][0]].to(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fa037b-0009-44f3-882a-a7936ea6cb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "for box in nearest_boxes:\n",
    "    box = box.numpy()\n",
    "    img = cv2.rectangle(img, (box[0], box[1]),\n",
    "                        (box[2], box[3]),\n",
    "                        (0, 255, 0), 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429e7d87-a6c8-4a22-a31b-6d3e23915b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 12))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5604fc-2d95-495f-b72f-14181af0b1df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2baf0dd9-d712-4c14-87e3-50e8f23edef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giakhang/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1708025539291/work/aten/src/ATen/native/TensorShape.cpp:3550.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "model.training = False\n",
    "img = model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82fc0e2e-869a-48b1-9bb2-64c0e83cfba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'instances': Instances(num_instances=0, image_height=375, image_width=1242, fields=[pred_boxes: Boxes(tensor([], size=(0, 4), grad_fn=<ViewBackward0>)), scores: tensor([], grad_fn=<IndexBackward0>), pred_classes: tensor([], dtype=torch.int64)])}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7290ad68-af8d-4a44-864c-9bfab638cd6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
