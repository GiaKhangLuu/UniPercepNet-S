{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07c4ec7d-39b8-459f-ab54-8d69261f7475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvcc\n",
      "torch:  2.2 ; cuda:  2.2.1\n",
      "detectron2: 0.6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch, detectron2\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6fe3cc0-2845-4a34-b0d5-cc7992e54661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "#from google.colab.patches import cv2_imshow\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "from detectron2.data.datasets import register_coco_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6878b07a-9381-46a2-b6cc-bc01cc7409b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'cityscapes'\n",
    "annot_dir = './cityscapes/annotations'\n",
    "imgs_dir = './cityscapes'\n",
    "\n",
    "for split in ['train', 'val']:\n",
    "    #if split == 'train':\n",
    "        #annot_path = '/kaggle/working/hope_to_public_net/instancesonly_filtered_gtFine_train_temp.json'\n",
    "    #else:\n",
    "    annot_path = os.path.join(annot_dir, f'instancesonly_filtered_gtFine_{split}.json')\n",
    "    d_name = dataset + f'_{split}'\n",
    "    register_coco_instances(d_name, {}, annot_path, imgs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25e61cc6-b822-4a83-8377-5386f50f7bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[04/13 16:03:39 d2.data.datasets.coco]: \u001b[0mLoading ./cityscapes/annotations/instancesonly_filtered_gtFine_train.json takes 2.25 seconds.\n",
      "\u001b[32m[04/13 16:03:39 d2.data.datasets.coco]: \u001b[0mLoaded 2975 images in COCO format from ./cityscapes/annotations/instancesonly_filtered_gtFine_train.json\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'cityscapes_train'\n",
    "\n",
    "# Load dataset\n",
    "dataset_dicts = DatasetCatalog.get(dataset_name)\n",
    "metadata = MetadataCatalog.get(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b628ca1-932f-4485-90e4-68cc8f552095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "class Args(argparse.Namespace):\n",
    "    config_file='khang_net/configs/huflit_net/huflit_net_1x.py'\n",
    "    eval_only=False\n",
    "    num_gpus=1\n",
    "    num_machines=1\n",
    "    resume=True\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2b167a0-4ef9-4e52-b998-2fabefe7adf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.model_zoo import get_config\n",
    "from detectron2.config import LazyConfig\n",
    "from detectron2.config.instantiate import instantiate\n",
    "\n",
    "cfg = LazyConfig.load(\"khang_net/configs/huflit_net/huflit_net_1x.py\")\n",
    "cfg.train.device = 'mps'\n",
    "cfg.dataloader.evaluator.dataset_name = 'cityscapes_val'\n",
    "cfg.dataloader.train.dataset.names = 'cityscapes_train'\n",
    "cfg.dataloader.test.dataset.names = 'cityscapes_val'\n",
    "cfg.dataloader.train.total_batch_size = 16\n",
    "\n",
    "\"\"\"\n",
    "batch_on_paper = 16\n",
    "actual_batch = cfg.dataloader.train.total_batch_size\n",
    "lr_scale = actual_batch / batch_on_paper\n",
    "cfg.optimizer.lr = cfg.optimizer.lr * lr_scale\n",
    "cfg.optimizer.params.base_lr = cfg.optimizer.params.base_lr * lr_scale\n",
    "cfg.optimizer.params.bias_lr_factor = cfg.optimizer.params.bias_lr_factor * lr_scale\n",
    "cfg.optimizer.params.backbone_lr_factor = cfg.optimizer.params.backbone_lr_factor * lr_scale\n",
    "\"\"\"\n",
    "\n",
    "cfg.model.num_classes = 8\n",
    "cfg.model.yolof.num_classes = 8\n",
    "cfg.model.mask_head.num_classes = 8\n",
    "\n",
    "#cfg.train.eval_period = 100000\n",
    "#cfg.train.checkpointer.period = 1000\n",
    "cfg.model.yolof_weight = None\n",
    "cfg.model.train_yolof = True\n",
    "\n",
    "cfg.optimizer.params.base_lr = 0.01\n",
    "cfg.optimizer.lr = 0.01\n",
    "\n",
    "cfg.train.max_iter = 30000\n",
    "#cfg.train.init_checkpoint = '/Users/giakhang/Downloads/huflitnet_10k_iters/last_checkpoint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66b0a99c-4ed2-49f3-8137-dd35ec5d5f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[04/13 16:03:45 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
      "\u001b[32m[04/13 16:03:45 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
      "\u001b[32m[04/13 16:03:46 detectron2]: \u001b[0mEnvironment info:\n",
      "-------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "sys.platform                     darwin\n",
      "Python                           3.9.18 | packaged by conda-forge | (main, Dec 23 2023, 16:35:41) [Clang 16.0.6 ]\n",
      "numpy                            1.26.4\n",
      "detectron2                       0.6 @/Users/giakhang/dev/work/sand_box/hope_to_public_net/detectron2/detectron2\n",
      "detectron2._C                    not built correctly: dlopen(/Users/giakhang/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/_C.cpython-39-darwin.so, 0x0002): tried: '/opt/homebrew/opt/libomp/lib/_C.cpython-39-darwin.so' (no such file), '/_C.cpython-39-darwin.so' (no such file), '/Users/giakhang/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/_C.cpython-39-darwin.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64')), '/System/Volumes/Preboot/Cryptexes/OS/Users/giakhang/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/_C.cpython-39-darwin.so' (no such file), '/Users/giakhang/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/_C.cpython-39-darwin.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64'))\n",
      "Compiler ($CXX)                  Apple clang version 14.0.3 (clang-1403.0.22.14.1)\n",
      "DETECTRON2_ENV_MODULE            <not set>\n",
      "PyTorch                          2.2.1 @/Users/giakhang/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch\n",
      "PyTorch debug build              False\n",
      "torch._C._GLIBCXX_USE_CXX11_ABI  False\n",
      "GPU available                    No: torch.cuda.is_available() == False\n",
      "Pillow                           10.2.0\n",
      "torchvision                      0.17.1 @/Users/giakhang/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torchvision\n",
      "fvcore                           0.1.5.post20221221\n",
      "iopath                           0.1.9\n",
      "cv2                              4.9.0\n",
      "-------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PyTorch built with:\n",
      "  - GCC 4.2\n",
      "  - C++ Version: 201703\n",
      "  - clang 13.1.6\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: NO AVX\n",
      "  - Build settings: BLAS_INFO=accelerate, BUILD_TYPE=Release, CXX_COMPILER=/Applications/Xcode_13.3.1.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang++, CXX_FLAGS= -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_PYTORCH_METAL_EXPORT -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DUSE_COREML_DELEGATE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=braced-scalar-init -Werror=range-loop-construct -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wvla-extension -Wsuggest-override -Wnewline-eof -Winconsistent-missing-override -Winconsistent-missing-destructor-override -Wno-pass-failed -Wno-error=pedantic -Wno-error=old-style-cast -Wno-error=inconsistent-missing-override -Wno-error=inconsistent-missing-destructor-override -Wconstant-conversion -Wno-invalid-partial-specialization -Wno-missing-braces -Qunused-arguments -fcolor-diagnostics -faligned-new -Wno-unused-but-set-variable -fno-math-errno -fno-trapping-math -Werror=format -DUSE_MPS -Wno-unused-private-field -Wno-missing-braces, LAPACK_INFO=accelerate, TORCH_VERSION=2.2.1, USE_CUDA=0, USE_CUDNN=OFF, USE_EIGEN_FOR_BLAS=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=OFF, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=ON, USE_OPENMP=OFF, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \n",
      "\n",
      "\u001b[32m[04/13 16:03:46 detectron2]: \u001b[0mEnvironment info:\n",
      "-------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "sys.platform                     darwin\n",
      "Python                           3.9.18 | packaged by conda-forge | (main, Dec 23 2023, 16:35:41) [Clang 16.0.6 ]\n",
      "numpy                            1.26.4\n",
      "detectron2                       0.6 @/Users/giakhang/dev/work/sand_box/hope_to_public_net/detectron2/detectron2\n",
      "detectron2._C                    not built correctly: dlopen(/Users/giakhang/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/_C.cpython-39-darwin.so, 0x0002): tried: '/opt/homebrew/opt/libomp/lib/_C.cpython-39-darwin.so' (no such file), '/_C.cpython-39-darwin.so' (no such file), '/Users/giakhang/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/_C.cpython-39-darwin.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64')), '/System/Volumes/Preboot/Cryptexes/OS/Users/giakhang/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/_C.cpython-39-darwin.so' (no such file), '/Users/giakhang/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/_C.cpython-39-darwin.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64'))\n",
      "Compiler ($CXX)                  Apple clang version 14.0.3 (clang-1403.0.22.14.1)\n",
      "DETECTRON2_ENV_MODULE            <not set>\n",
      "PyTorch                          2.2.1 @/Users/giakhang/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch\n",
      "PyTorch debug build              False\n",
      "torch._C._GLIBCXX_USE_CXX11_ABI  False\n",
      "GPU available                    No: torch.cuda.is_available() == False\n",
      "Pillow                           10.2.0\n",
      "torchvision                      0.17.1 @/Users/giakhang/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torchvision\n",
      "fvcore                           0.1.5.post20221221\n",
      "iopath                           0.1.9\n",
      "cv2                              4.9.0\n",
      "-------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PyTorch built with:\n",
      "  - GCC 4.2\n",
      "  - C++ Version: 201703\n",
      "  - clang 13.1.6\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: NO AVX\n",
      "  - Build settings: BLAS_INFO=accelerate, BUILD_TYPE=Release, CXX_COMPILER=/Applications/Xcode_13.3.1.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang++, CXX_FLAGS= -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_PYTORCH_METAL_EXPORT -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DUSE_COREML_DELEGATE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=braced-scalar-init -Werror=range-loop-construct -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wvla-extension -Wsuggest-override -Wnewline-eof -Winconsistent-missing-override -Winconsistent-missing-destructor-override -Wno-pass-failed -Wno-error=pedantic -Wno-error=old-style-cast -Wno-error=inconsistent-missing-override -Wno-error=inconsistent-missing-destructor-override -Wconstant-conversion -Wno-invalid-partial-specialization -Wno-missing-braces -Qunused-arguments -fcolor-diagnostics -faligned-new -Wno-unused-but-set-variable -fno-math-errno -fno-trapping-math -Werror=format -DUSE_MPS -Wno-unused-private-field -Wno-missing-braces, LAPACK_INFO=accelerate, TORCH_VERSION=2.2.1, USE_CUDA=0, USE_CUDNN=OFF, USE_EIGEN_FOR_BLAS=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=OFF, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=ON, USE_OPENMP=OFF, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \n",
      "\n",
      "\u001b[32m[04/13 16:03:46 detectron2]: \u001b[0mCommand line arguments: Args()\n",
      "\u001b[32m[04/13 16:03:46 detectron2]: \u001b[0mCommand line arguments: Args()\n",
      "\u001b[32m[04/13 16:03:46 detectron2]: \u001b[0mContents of args.config_file=khang_net/configs/huflit_net/huflit_net_1x.py:\n",
      "\u001b[38;5;245m#from detectron2.model_zoo.configs.common.train import train\u001b[39m\n",
      "\n",
      "\u001b[38;5;204mfrom\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mkhang_net\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mconfigs\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mhuflit_net\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mtrain\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204mimport\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mtrain\u001b[39m\n",
      "\u001b[38;5;204mfrom\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mkhang_net\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mconfigs\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15myolof\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15moptim\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204mimport\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mYOLOF_SGD\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;81mas\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15moptimizer\u001b[39m\n",
      "\u001b[38;5;204mfrom\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mkhang_net\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mconfigs\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15myolof\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mcoco_schedule\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204mimport\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mlr_multiplier_1x\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;81mas\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mlr_multiplier\u001b[39m\n",
      "\u001b[38;5;204mfrom\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mkhang_net\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mconfigs\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15myolof\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mcoco_dataloader\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204mimport\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mdataloader\u001b[39m\n",
      "\u001b[38;5;204mfrom\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mkhang_net\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mconfigs\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mhuflit_net\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mbase_huflitnet\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204mimport\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mmodel\u001b[39m\n",
      "\n",
      "\n",
      "\u001b[38;5;15mdataloader\u001b[39m\u001b[38;5;204m.\u001b[39m\u001b[38;5;15mtrain\u001b[39m\u001b[38;5;204m.\u001b[39m\u001b[38;5;15mmapper\u001b[39m\u001b[38;5;204m.\u001b[39m\u001b[38;5;15muse_instance_mask\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204m=\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;81mTrue\u001b[39m\n",
      "\n",
      "\u001b[38;5;15mmodel\u001b[39m\u001b[38;5;204m.\u001b[39m\u001b[38;5;15myolof\u001b[39m\u001b[38;5;204m.\u001b[39m\u001b[38;5;15mbackbone\u001b[39m\u001b[38;5;204m.\u001b[39m\u001b[38;5;15mfreeze_at\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204m=\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;141m2\u001b[39m\n",
      "\n",
      "\u001b[38;5;15mtrain\u001b[39m\u001b[38;5;15m[\u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;186minit_checkpoint\u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;15m]\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204m=\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
      "\n",
      "\u001b[32m[04/13 16:03:46 detectron2]: \u001b[0mContents of args.config_file=khang_net/configs/huflit_net/huflit_net_1x.py:\n",
      "\u001b[38;5;245m#from detectron2.model_zoo.configs.common.train import train\u001b[39m\n",
      "\n",
      "\u001b[38;5;204mfrom\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mkhang_net\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mconfigs\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mhuflit_net\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mtrain\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204mimport\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mtrain\u001b[39m\n",
      "\u001b[38;5;204mfrom\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mkhang_net\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mconfigs\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15myolof\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15moptim\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204mimport\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mYOLOF_SGD\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;81mas\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15moptimizer\u001b[39m\n",
      "\u001b[38;5;204mfrom\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mkhang_net\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mconfigs\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15myolof\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mcoco_schedule\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204mimport\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mlr_multiplier_1x\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;81mas\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mlr_multiplier\u001b[39m\n",
      "\u001b[38;5;204mfrom\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mkhang_net\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mconfigs\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15myolof\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mcoco_dataloader\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204mimport\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mdataloader\u001b[39m\n",
      "\u001b[38;5;204mfrom\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mkhang_net\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mconfigs\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mhuflit_net\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mbase_huflitnet\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204mimport\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mmodel\u001b[39m\n",
      "\n",
      "\n",
      "\u001b[38;5;15mdataloader\u001b[39m\u001b[38;5;204m.\u001b[39m\u001b[38;5;15mtrain\u001b[39m\u001b[38;5;204m.\u001b[39m\u001b[38;5;15mmapper\u001b[39m\u001b[38;5;204m.\u001b[39m\u001b[38;5;15muse_instance_mask\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204m=\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;81mTrue\u001b[39m\n",
      "\n",
      "\u001b[38;5;15mmodel\u001b[39m\u001b[38;5;204m.\u001b[39m\u001b[38;5;15myolof\u001b[39m\u001b[38;5;204m.\u001b[39m\u001b[38;5;15mbackbone\u001b[39m\u001b[38;5;204m.\u001b[39m\u001b[38;5;15mfreeze_at\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204m=\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;141m2\u001b[39m\n",
      "\n",
      "\u001b[38;5;15mtrain\u001b[39m\u001b[38;5;15m[\u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;186minit_checkpoint\u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;15m]\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204m=\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
      "\n",
      "\u001b[32m[04/13 16:03:46 detectron2]: \u001b[0mFull config saved to ./output/config.yaml\n",
      "\u001b[32m[04/13 16:03:46 detectron2]: \u001b[0mFull config saved to ./output/config.yaml\n",
      "\u001b[32m[04/13 16:03:46 d2.utils.env]: \u001b[0mUsing a generated random seed 46686142\n",
      "\u001b[32m[04/13 16:03:46 d2.utils.env]: \u001b[0mUsing a generated random seed 46686142\n"
     ]
    }
   ],
   "source": [
    "from detectron2.engine import default_setup\n",
    "\n",
    "default_setup(cfg, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99ab83d7-92fd-4c8c-b66f-3b855a480830",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp /Users/giakhang/Downloads/huflit_net_20k_iters/last_checkpoint ./output\n",
    "!cp /Users/giakhang/Downloads/huflit_net_20k_iters/model_final.pth ./output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d83405a5-b5e8-4948-8b2c-5f67409c96ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[04/13 16:07:43 detectron2]: \u001b[0mModel:\n",
      "HUFLIT_Net(\n",
      "  (yolof): YOLOF(\n",
      "    (backbone): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (encoder): DilatedEncoder(\n",
      "      (lateral_conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (lateral_norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "      (fpn_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (fpn_norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "      (dilated_encoder_blocks): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Sequential(\n",
      "            (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): Sequential(\n",
      "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
      "            (1): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv3): Sequential(\n",
      "            (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Sequential(\n",
      "            (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): Sequential(\n",
      "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
      "            (1): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv3): Sequential(\n",
      "            (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Sequential(\n",
      "            (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): Sequential(\n",
      "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
      "            (1): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv3): Sequential(\n",
      "            (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Sequential(\n",
      "            (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): Sequential(\n",
      "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8))\n",
      "            (1): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv3): Sequential(\n",
      "            (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoder): YOLOFDecoder(\n",
      "      (cls_subnet): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "      (bbox_subnet): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (7): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        (8): ReLU(inplace=True)\n",
      "        (9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (10): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        (11): ReLU(inplace=True)\n",
      "      )\n",
      "      (cls_score): Conv2d(512, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bbox_pred): Conv2d(512, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (object_pred): Conv2d(512, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): YOLOFAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "    (anchor_matcher): UniformMatcher()\n",
      "  )\n",
      "  (pooler): ROIPooler(\n",
      "    (level_poolers): ModuleList(\n",
      "      (0): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "    )\n",
      "  )\n",
      "  (mask_head): MaskRCNNConvUpsampleHead(\n",
      "    (mask_fcn1): Conv2d(\n",
      "      512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (mask_fcn2): Conv2d(\n",
      "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (mask_fcn3): Conv2d(\n",
      "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (mask_fcn4): Conv2d(\n",
      "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (deconv_relu): ReLU()\n",
      "    (predictor): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\u001b[32m[04/13 16:07:43 detectron2]: \u001b[0mModel:\n",
      "HUFLIT_Net(\n",
      "  (yolof): YOLOF(\n",
      "    (backbone): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (encoder): DilatedEncoder(\n",
      "      (lateral_conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (lateral_norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "      (fpn_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (fpn_norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "      (dilated_encoder_blocks): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Sequential(\n",
      "            (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): Sequential(\n",
      "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
      "            (1): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv3): Sequential(\n",
      "            (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Sequential(\n",
      "            (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): Sequential(\n",
      "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
      "            (1): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv3): Sequential(\n",
      "            (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Sequential(\n",
      "            (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): Sequential(\n",
      "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
      "            (1): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv3): Sequential(\n",
      "            (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Sequential(\n",
      "            (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): Sequential(\n",
      "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8))\n",
      "            (1): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv3): Sequential(\n",
      "            (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoder): YOLOFDecoder(\n",
      "      (cls_subnet): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "      (bbox_subnet): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (7): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        (8): ReLU(inplace=True)\n",
      "        (9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (10): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        (11): ReLU(inplace=True)\n",
      "      )\n",
      "      (cls_score): Conv2d(512, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bbox_pred): Conv2d(512, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (object_pred): Conv2d(512, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): YOLOFAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "    (anchor_matcher): UniformMatcher()\n",
      "  )\n",
      "  (pooler): ROIPooler(\n",
      "    (level_poolers): ModuleList(\n",
      "      (0): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "    )\n",
      "  )\n",
      "  (mask_head): MaskRCNNConvUpsampleHead(\n",
      "    (mask_fcn1): Conv2d(\n",
      "      512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (mask_fcn2): Conv2d(\n",
      "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (mask_fcn3): Conv2d(\n",
      "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (mask_fcn4): Conv2d(\n",
      "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (deconv_relu): ReLU()\n",
      "    (predictor): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\u001b[32m[04/13 16:07:47 d2.data.datasets.coco]: \u001b[0mLoading ./cityscapes/annotations/instancesonly_filtered_gtFine_train.json takes 3.93 seconds.\n",
      "\u001b[32m[04/13 16:07:47 d2.data.datasets.coco]: \u001b[0mLoading ./cityscapes/annotations/instancesonly_filtered_gtFine_train.json takes 3.93 seconds.\n",
      "\u001b[32m[04/13 16:07:47 d2.data.datasets.coco]: \u001b[0mLoaded 2975 images in COCO format from ./cityscapes/annotations/instancesonly_filtered_gtFine_train.json\n",
      "\u001b[32m[04/13 16:07:47 d2.data.datasets.coco]: \u001b[0mLoaded 2975 images in COCO format from ./cityscapes/annotations/instancesonly_filtered_gtFine_train.json\n",
      "\u001b[32m[04/13 16:07:49 d2.data.build]: \u001b[0mRemoved 10 images with no usable annotations. 2965 images left.\n",
      "\u001b[32m[04/13 16:07:49 d2.data.build]: \u001b[0mRemoved 10 images with no usable annotations. 2965 images left.\n",
      "\u001b[32m[04/13 16:07:49 d2.data.build]: \u001b[0mDistribution of instances among all 8 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|   person   | 17395        |    car     | 26180        |   truck    | 466          |\n",
      "|   rider    | 1660         | motorcycle | 705          |  bicycle   | 3433         |\n",
      "|    bus     | 350          |   train    | 158          |            |              |\n",
      "|   total    | 50347        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[04/13 16:07:49 d2.data.build]: \u001b[0mDistribution of instances among all 8 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|   person   | 17395        |    car     | 26180        |   truck    | 466          |\n",
      "|   rider    | 1660         | motorcycle | 705          |  bicycle   | 3433         |\n",
      "|    bus     | 350          |   train    | 158          |            |              |\n",
      "|   total    | 50347        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[04/13 16:07:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=[800], max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[04/13 16:07:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=[800], max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[04/13 16:07:49 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[04/13 16:07:49 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[04/13 16:07:49 d2.data.common]: \u001b[0mSerializing 2965 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/13 16:07:49 d2.data.common]: \u001b[0mSerializing 2965 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/13 16:07:50 d2.data.common]: \u001b[0mSerialized dataset takes 97.08 MiB\n",
      "\u001b[32m[04/13 16:07:50 d2.data.common]: \u001b[0mSerialized dataset takes 97.08 MiB\n",
      "\u001b[32m[04/13 16:07:50 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=16\n",
      "\u001b[32m[04/13 16:07:50 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=16\n",
      "*********\n",
      "./output/last_checkpoint\n",
      "\u001b[32m[04/13 16:07:50 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from ./output/model_final.pth ...\n",
      "\u001b[32m[04/13 16:07:50 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from ./output/model_final.pth ...\n",
      "\u001b[32m[04/13 16:07:50 fvcore.common.checkpoint]: \u001b[0m[Checkpointer] Loading from ./output/model_final.pth ...\n",
      "\u001b[32m[04/13 16:07:50 fvcore.common.checkpoint]: \u001b[0mLoading trainer from ./output/model_final.pth ...\n",
      "*********\n",
      "./output/last_checkpoint\n",
      "\u001b[32m[04/13 16:07:50 d2.engine.train_loop]: \u001b[0mStarting training from iteration 20000\n",
      "\u001b[32m[04/13 16:07:50 d2.engine.train_loop]: \u001b[0mStarting training from iteration 20000\n",
      "\u001b[4m\u001b[5m\u001b[31mERROR\u001b[0m \u001b[32m[04/13 16:08:31 d2.engine.train_loop]: \u001b[0mException during training:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/giakhang/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/engine/train_loop.py\", line 155, in train\n",
      "    self.run_step()\n",
      "  File \"/Users/giakhang/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/engine/train_loop.py\", line 310, in run_step\n",
      "    loss_dict = self.model(data)\n",
      "  File \"/Users/giakhang/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/giakhang/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/giakhang/dev/work/sand_box/hope_to_public_net/khang_net/modeling/meta_arch/huflit_net.py\", line 187, in forward\n",
      "    features = self.yolof.backbone(images.tensor)\n",
      "  File \"/Users/giakhang/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/giakhang/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/giakhang/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/modeling/backbone/resnet.py\", line 449, in forward\n",
      "    x = stage(x)\n",
      "  File \"/Users/giakhang/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/giakhang/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/giakhang/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 217, in forward\n",
      "    input = module(input)\n",
      "  File \"/Users/giakhang/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/giakhang/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/giakhang/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/modeling/backbone/resnet.py\", line 201, in forward\n",
      "    out = self.conv3(out)\n",
      "  File \"/Users/giakhang/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/giakhang/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/giakhang/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/layers/wrappers.py\", line 131, in forward\n",
      "    x = self.norm(x)\n",
      "  File \"/Users/giakhang/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/giakhang/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/giakhang/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/layers/batch_norm.py\", line 54, in forward\n",
      "    return x * scale.to(out_dtype) + bias.to(out_dtype)\n",
      "RuntimeError: MPS backend out of memory (MPS allocated: 6.76 GB, other allocations: 2.09 GB, max allowed: 9.07 GB). Tried to allocate 220.50 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).\n",
      "\u001b[4m\u001b[5m\u001b[31mERROR\u001b[0m \u001b[32m[04/13 16:08:31 d2.engine.train_loop]: \u001b[0mException during training:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/giakhang/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/engine/train_loop.py\", line 155, in train\n",
      "    self.run_step()\n",
      "  File \"/Users/giakhang/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/engine/train_loop.py\", line 310, in run_step\n",
      "    loss_dict = self.model(data)\n",
      "  File \"/Users/giakhang/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/giakhang/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/giakhang/dev/work/sand_box/hope_to_public_net/khang_net/modeling/meta_arch/huflit_net.py\", line 187, in forward\n",
      "    features = self.yolof.backbone(images.tensor)\n",
      "  File \"/Users/giakhang/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/giakhang/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/giakhang/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/modeling/backbone/resnet.py\", line 449, in forward\n",
      "    x = stage(x)\n",
      "  File \"/Users/giakhang/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/giakhang/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/giakhang/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 217, in forward\n",
      "    input = module(input)\n",
      "  File \"/Users/giakhang/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/giakhang/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/giakhang/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/modeling/backbone/resnet.py\", line 201, in forward\n",
      "    out = self.conv3(out)\n",
      "  File \"/Users/giakhang/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/giakhang/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/giakhang/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/layers/wrappers.py\", line 131, in forward\n",
      "    x = self.norm(x)\n",
      "  File \"/Users/giakhang/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/giakhang/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/giakhang/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/layers/batch_norm.py\", line 54, in forward\n",
      "    return x * scale.to(out_dtype) + bias.to(out_dtype)\n",
      "RuntimeError: MPS backend out of memory (MPS allocated: 6.76 GB, other allocations: 2.09 GB, max allowed: 9.07 GB). Tried to allocate 220.50 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).\n",
      "\u001b[32m[04/13 16:08:32 d2.engine.hooks]: \u001b[0mTotal training time: 0:00:41 (0:00:00 on hooks)\n",
      "\u001b[32m[04/13 16:08:32 d2.engine.hooks]: \u001b[0mTotal training time: 0:00:41 (0:00:00 on hooks)\n",
      "\u001b[32m[04/13 16:08:32 d2.utils.events]: \u001b[0m iter: 20000       lr: N/A  \n",
      "\u001b[32m[04/13 16:08:32 d2.utils.events]: \u001b[0m iter: 20000       lr: N/A  \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 6.76 GB, other allocations: 2.09 GB, max allowed: 9.07 GB). Tried to allocate 220.50 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkhang_net\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazyconfig_train_net\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m do_train\n\u001b[0;32m----> 3\u001b[0m \u001b[43mdo_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/work/sand_box/hope_to_public_net/khang_net/lazyconfig_train_net.py:109\u001b[0m, in \u001b[0;36mdo_train\u001b[0;34m(args, cfg)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    108\u001b[0m     start_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 109\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/engine/train_loop.py:155\u001b[0m, in \u001b[0;36mTrainerBase.train\u001b[0;34m(self, start_iter, max_iter)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_iter, max_iter):\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbefore_step()\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter_step()\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# self.iter == max_iter can be used by `after_train` to\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# tell whether the training successfully finished or failed\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# due to exceptions.\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/engine/train_loop.py:310\u001b[0m, in \u001b[0;36mSimpleTrainer.run_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    307\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;124;03mIf you want to do something with the losses, you can wrap the model.\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m loss_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loss_dict, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    312\u001b[0m     losses \u001b[38;5;241m=\u001b[39m loss_dict\n",
      "File \u001b[0;32m~/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/work/sand_box/hope_to_public_net/khang_net/modeling/meta_arch/huflit_net.py:187\u001b[0m, in \u001b[0;36mHUFLIT_Net.forward\u001b[0;34m(self, batched_inputs)\u001b[0m\n\u001b[1;32m    180\u001b[0m images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_image(batched_inputs)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m#if \"instances\" in batched_inputs[0]:\u001b[39;00m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;66;03m#gt_instances = [x[\"instances\"].to(self.device) for x in batched_inputs]\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m#else:\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m#gt_instances = None\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m#features = self.backbone(images.tensor)\u001b[39;00m\n\u001b[0;32m--> 187\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43myolof\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m features \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mres5\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Pass `p5` (output from encoder) to roi pooler\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# Temporarily hard code this now, haven't modify in config file\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/modeling/backbone/resnet.py:449\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    447\u001b[0m     outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstem\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, stage \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstage_names, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstages):\n\u001b[0;32m--> 449\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mstage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_out_features:\n\u001b[1;32m    451\u001b[0m         outputs[name] \u001b[38;5;241m=\u001b[39m x\n",
      "File \u001b[0;32m~/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/modeling/backbone/resnet.py:201\u001b[0m, in \u001b[0;36mBottleneckBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    198\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(out)\n\u001b[1;32m    199\u001b[0m out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu_(out)\n\u001b[0;32m--> 201\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshortcut \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    204\u001b[0m     shortcut \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshortcut(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/layers/wrappers.py:131\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    127\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    128\u001b[0m     x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups\n\u001b[1;32m    129\u001b[0m )\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 131\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/layers/batch_norm.py:54\u001b[0m, in \u001b[0;36mFrozenBatchNorm2d.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     52\u001b[0m     bias \u001b[38;5;241m=\u001b[39m bias\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     53\u001b[0m     out_dtype \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mdtype  \u001b[38;5;66;03m# may be half\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# When gradients are not needed, F.batch_norm is a single fused op\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;66;03m# and provide more optimization opportunities.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mbatch_norm(\n\u001b[1;32m     59\u001b[0m         x,\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m         eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps,\n\u001b[1;32m     66\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 6.76 GB, other allocations: 2.09 GB, max allowed: 9.07 GB). Tried to allocate 220.50 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "from khang_net.lazyconfig_train_net import do_train\n",
    "\n",
    "do_train(args, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e615933-fc2c-4034-a2ff-7e5c8e118ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6846b2ef-5e49-4978-9b1d-6bdbb1cc4976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists('./output/last_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98144356-fcb3-46bd-ae31-f4e14a2c66eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 25752\n",
      "drwxr-xr-x@ 22 giakhang  staff      704 Apr 13 15:59 \u001b[1m\u001b[36m.\u001b[m\u001b[m\n",
      "drwxr-xr-x@  6 giakhang  staff      192 Feb 29 11:03 \u001b[1m\u001b[36m..\u001b[m\u001b[m\n",
      "-rw-r--r--   1 giakhang  staff    10244 Apr 13 15:54 .DS_Store\n",
      "drwxr-xr-x  15 giakhang  staff      480 Apr 12 12:17 \u001b[1m\u001b[36m.git\u001b[m\u001b[m\n",
      "-rw-r--r--   1 giakhang  staff       32 Apr  4 22:32 .gitignore\n",
      "drwxr-xr-x@  8 giakhang  staff      256 Apr  8 09:51 \u001b[1m\u001b[36m.ipynb_checkpoints\u001b[m\u001b[m\n",
      "drwxr-xr-x@  3 giakhang  staff       96 Mar  8 16:39 \u001b[1m\u001b[36m.vscode\u001b[m\u001b[m\n",
      "-rw-r--r--   1 giakhang  staff  2476527 Apr  4 22:32 HUFLIT_Net.ipynb\n",
      "-rw-r--r--   1 giakhang  staff        0 Feb 29 11:18 README.md\n",
      "-rw-r--r--@  1 giakhang  staff    79303 Apr 13 15:59 Resume training.ipynb\n",
      "lrwxr-xr-x   1 giakhang  staff       66 Feb 29 11:16 \u001b[35mcityscapes\u001b[m\u001b[m -> /Users/giakhang/dev/work/research_autopilot/dataset_zoo/cityscapes\n",
      "drwxr-xr-x@ 27 giakhang  staff      864 Apr  4 22:32 \u001b[1m\u001b[36mdetectron2\u001b[m\u001b[m\n",
      "-rw-r--r--   1 giakhang  staff  2648564 Apr  4 22:32 inside_maskrcnn.ipynb\n",
      "drwxr-xr-x@  8 giakhang  staff      256 Apr  5 10:00 \u001b[1m\u001b[36mkhang_net\u001b[m\u001b[m\n",
      "lrwxr-xr-x@  1 giakhang  staff       61 Mar  8 16:39 \u001b[35mkitti\u001b[m\u001b[m -> /Users/giakhang/dev/work/research_autopilot/dataset_zoo/kitti\n",
      "drwxr-xr-x@  7 giakhang  staff      224 Apr 13 15:57 \u001b[1m\u001b[36moutput\u001b[m\u001b[m\n",
      "lrwxr-xr-x@  1 giakhang  staff       50 Mar 20 22:28 \u001b[35moutput_yolof_uni_matcher\u001b[m\u001b[m -> /Users/giakhang/Downloads/output_yolof_uni_matcher\n",
      "-rw-r--r--   1 giakhang  staff      900 Apr 12 13:42 setup_package_thue_gpu.sh\n",
      "-rw-r--r--   1 giakhang  staff     2599 Apr 12 11:47 train_huflitnet.py\n",
      "-rw-r--r--   1 giakhang  staff   450112 Apr  4 22:32 yolof_10_03.ipynb\n",
      "-rw-r--r--   1 giakhang  staff  3417331 Apr  4 22:32 yolof_uni_matcher.ipynb\n",
      "-rw-r--r--   1 giakhang  staff  4077088 Apr  4 22:32 yolof_with_mask.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls -al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6033f3-9727-432a-b6c6-b472e5e4f8c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b592999a-2cfb-471f-8957-ec0e4753d082",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
