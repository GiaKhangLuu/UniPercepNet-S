{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d778213-2cc6-4928-b680-b6b5955df7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "class Args(argparse.Namespace):\n",
    "    config_file='khang_net/configs/yolof/yolof_resnet_50_1x.py'\n",
    "    eval_only=False\n",
    "    num_gpus=1\n",
    "    num_machines=1\n",
    "    resume=False\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67f3f834-cba4-4196-aa3e-c025b5fe6ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.model_zoo import get_config\n",
    "from detectron2.config import LazyConfig\n",
    "from detectron2.config.instantiate import instantiate\n",
    "\n",
    "cfg = LazyConfig.load(\"khang_net/configs/yolof/yolof_resnet_50_1x.py\")\n",
    "cfg.train.device = 'mps'\n",
    "cfg.dataloader.evaluator.dataset_name = 'kitti_val'\n",
    "cfg.dataloader.train.dataset.names = 'kitti_train'\n",
    "\n",
    "cfg.dataloader.train.total_batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fac5615-ae2d-4623-9605-5aee698aa3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import default_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74a437be-df06-4770-9306-6e46443189a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/10 15:00:08 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
      "\u001b[32m[03/10 15:00:08 detectron2]: \u001b[0mEnvironment info:\n",
      "-------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "sys.platform                     darwin\n",
      "Python                           3.9.18 | packaged by conda-forge | (main, Dec 23 2023, 16:35:41) [Clang 16.0.6 ]\n",
      "numpy                            1.26.4\n",
      "detectron2                       0.6 @/Users/giakhang/dev/work/sand_box/hope_to_public_net/detectron2/detectron2\n",
      "detectron2._C                    not built correctly: dlopen(/Users/giakhang/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/_C.cpython-39-darwin.so, 0x0002): tried: '/opt/homebrew/opt/libomp/lib/_C.cpython-39-darwin.so' (no such file), '/_C.cpython-39-darwin.so' (no such file), '/Users/giakhang/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/_C.cpython-39-darwin.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64')), '/System/Volumes/Preboot/Cryptexes/OS/Users/giakhang/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/_C.cpython-39-darwin.so' (no such file), '/Users/giakhang/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/_C.cpython-39-darwin.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64'))\n",
      "Compiler ($CXX)                  Apple clang version 14.0.3 (clang-1403.0.22.14.1)\n",
      "DETECTRON2_ENV_MODULE            <not set>\n",
      "PyTorch                          2.2.1 @/Users/giakhang/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch\n",
      "PyTorch debug build              False\n",
      "torch._C._GLIBCXX_USE_CXX11_ABI  False\n",
      "GPU available                    No: torch.cuda.is_available() == False\n",
      "Pillow                           10.2.0\n",
      "torchvision                      0.17.1 @/Users/giakhang/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torchvision\n",
      "fvcore                           0.1.5.post20221221\n",
      "iopath                           0.1.9\n",
      "cv2                              4.9.0\n",
      "-------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PyTorch built with:\n",
      "  - GCC 4.2\n",
      "  - C++ Version: 201703\n",
      "  - clang 13.1.6\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: NO AVX\n",
      "  - Build settings: BLAS_INFO=accelerate, BUILD_TYPE=Release, CXX_COMPILER=/Applications/Xcode_13.3.1.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang++, CXX_FLAGS= -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_PYTORCH_METAL_EXPORT -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DUSE_COREML_DELEGATE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=braced-scalar-init -Werror=range-loop-construct -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wvla-extension -Wsuggest-override -Wnewline-eof -Winconsistent-missing-override -Winconsistent-missing-destructor-override -Wno-pass-failed -Wno-error=pedantic -Wno-error=old-style-cast -Wno-error=inconsistent-missing-override -Wno-error=inconsistent-missing-destructor-override -Wconstant-conversion -Wno-invalid-partial-specialization -Wno-missing-braces -Qunused-arguments -fcolor-diagnostics -faligned-new -Wno-unused-but-set-variable -fno-math-errno -fno-trapping-math -Werror=format -DUSE_MPS -Wno-unused-private-field -Wno-missing-braces, LAPACK_INFO=accelerate, TORCH_VERSION=2.2.1, USE_CUDA=0, USE_CUDNN=OFF, USE_EIGEN_FOR_BLAS=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=OFF, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=ON, USE_OPENMP=OFF, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \n",
      "\n",
      "\u001b[32m[03/10 15:00:08 detectron2]: \u001b[0mCommand line arguments: Args()\n",
      "\u001b[32m[03/10 15:00:08 detectron2]: \u001b[0mContents of args.config_file=khang_net/configs/yolof/yolof_resnet_50_1x.py:\n",
      "\u001b[38;5;204mfrom\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mdetectron2\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mmodel_zoo\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mconfigs\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mcommon\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15moptim\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204mimport\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mSGD\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;81mas\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15moptimizer\u001b[39m\n",
      "\u001b[38;5;204mfrom\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mdetectron2\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mmodel_zoo\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mconfigs\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mcommon\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mcoco_schedule\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204mimport\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mlr_multiplier_1x\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;81mas\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mlr_multiplier\u001b[39m\n",
      "\u001b[38;5;204mfrom\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mdetectron2\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mmodel_zoo\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mconfigs\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mcommon\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mdata\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mcoco\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204mimport\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mdataloader\u001b[39m\n",
      "\u001b[38;5;204mfrom\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mdetectron2\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mmodel_zoo\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mconfigs\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mcommon\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mtrain\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204mimport\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mtrain\u001b[39m\n",
      "\n",
      "\u001b[38;5;204mfrom\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mkhang_net\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mconfigs\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15myolof\u001b[39m\u001b[38;5;15m.\u001b[39m\u001b[38;5;15mbase_yolof\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204mimport\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mmodel\u001b[39m\n",
      "\n",
      "\u001b[38;5;15mdataloader\u001b[39m\u001b[38;5;204m.\u001b[39m\u001b[38;5;15mtrain\u001b[39m\u001b[38;5;204m.\u001b[39m\u001b[38;5;15mmapper\u001b[39m\u001b[38;5;204m.\u001b[39m\u001b[38;5;15muse_instance_mask\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204m=\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;81mFalse\u001b[39m\n",
      "\u001b[38;5;245m#model.backbone.bottom_up.freeze_at = 2\u001b[39m\n",
      "\u001b[38;5;15moptimizer\u001b[39m\u001b[38;5;204m.\u001b[39m\u001b[38;5;15mlr\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204m=\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;141m0.01\u001b[39m\n",
      "\n",
      "\u001b[38;5;15mtrain\u001b[39m\u001b[38;5;15m[\u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;186minit_checkpoint\u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;15m]\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;204m=\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
      "\n",
      "\u001b[32m[03/10 15:00:08 detectron2]: \u001b[0mFull config saved to ./output/config.yaml\n",
      "\u001b[32m[03/10 15:00:08 d2.utils.env]: \u001b[0mUsing a generated random seed 9012682\n"
     ]
    }
   ],
   "source": [
    "default_setup(cfg, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13f15475-f5d0-4725-80db-a77a2f4fba54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "\n",
    "dataset = 'kitti'\n",
    "annot_dir = './kitti/training_coco'\n",
    "imgs_dir = './kitti/training_voc/VOC2012/JPEGImages'\n",
    "\n",
    "for split in ['train', 'val']: \n",
    "    annot_path = os.path.join(annot_dir, f'{split}.json')\n",
    "    d_name = dataset + f'_{split}'\n",
    "    register_coco_instances(d_name, {}, annot_path, imgs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a66bede6-0780-4834-99e9-518cb780cf10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/10 15:00:15 d2.data.datasets.coco]: \u001b[0mLoaded 5984 images in COCO format from ./kitti/training_coco/train.json\n",
      "\u001b[32m[03/10 15:00:15 d2.data.datasets.coco]: \u001b[0mLoaded 5984 images in COCO format from ./kitti/training_coco/train.json\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset_dicts = DatasetCatalog.get('kitti_train')\n",
    "metadata = MetadataCatalog.get('kitti_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c7d7427-2745-4507-82a0-7057ebd555ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.train.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f0694d1-be90-4e9c-8f2c-631da0827303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/10 15:00:18 detectron2]: \u001b[0mModel:\n",
      "YOLOF(\n",
      "  (backbone): ResNet(\n",
      "    (stem): BasicStem(\n",
      "      (conv1): Conv2d(\n",
      "        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (res2): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res3): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (3): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res4): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (3): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (4): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (5): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res5): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): RetinaNetHead(\n",
      "    (cls_subnet): Sequential(\n",
      "      (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (bbox_subnet): Sequential(\n",
      "      (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (cls_score): Conv2d(256, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bbox_pred): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (anchor_generator): DefaultAnchorGenerator(\n",
      "    (cell_anchors): BufferList()\n",
      "  )\n",
      ")\n",
      "\u001b[32m[03/10 15:00:18 detectron2]: \u001b[0mModel:\n",
      "YOLOF(\n",
      "  (backbone): ResNet(\n",
      "    (stem): BasicStem(\n",
      "      (conv1): Conv2d(\n",
      "        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (res2): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res3): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (3): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res4): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (3): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (4): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (5): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res5): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): RetinaNetHead(\n",
      "    (cls_subnet): Sequential(\n",
      "      (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (bbox_subnet): Sequential(\n",
      "      (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (cls_score): Conv2d(256, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bbox_pred): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (anchor_generator): DefaultAnchorGenerator(\n",
      "    (cell_anchors): BufferList()\n",
      "  )\n",
      ")\n",
      "\u001b[32m[03/10 15:00:19 d2.data.datasets.coco]: \u001b[0mLoaded 5984 images in COCO format from ./kitti/training_coco/train.json\n",
      "\u001b[32m[03/10 15:00:19 d2.data.datasets.coco]: \u001b[0mLoaded 5984 images in COCO format from ./kitti/training_coco/train.json\n",
      "\u001b[32m[03/10 15:00:19 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 5984 images left.\n",
      "\u001b[32m[03/10 15:00:19 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 5984 images left.\n",
      "\u001b[32m[03/10 15:00:19 d2.data.build]: \u001b[0mDistribution of instances among all 9 categories:\n",
      "\u001b[36m|   category    | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:-------------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|    Cyclist    | 1311         |  DontCare  | 9027         |    Misc    | 759          |\n",
      "| Person_sitt.. | 184          |    Tram    | 405          |   Truck    | 872          |\n",
      "|      Van      | 2343         |    car     | 22873        |   person   | 3548         |\n",
      "|               |              |            |              |            |              |\n",
      "|     total     | 41322        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/10 15:00:19 d2.data.build]: \u001b[0mDistribution of instances among all 9 categories:\n",
      "\u001b[36m|   category    | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:-------------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|    Cyclist    | 1311         |  DontCare  | 9027         |    Misc    | 759          |\n",
      "| Person_sitt.. | 184          |    Tram    | 405          |   Truck    | 872          |\n",
      "|      Van      | 2343         |    car     | 22873        |   person   | 3548         |\n",
      "|               |              |            |              |            |              |\n",
      "|     total     | 41322        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/10 15:00:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=[640, 672, 704, 736, 768, 800], max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/10 15:00:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=[640, 672, 704, 736, 768, 800], max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/10 15:00:19 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[03/10 15:00:19 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[03/10 15:00:19 d2.data.common]: \u001b[0mSerializing 5984 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/10 15:00:19 d2.data.common]: \u001b[0mSerializing 5984 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/10 15:00:19 d2.data.common]: \u001b[0mSerialized dataset takes 2.49 MiB\n",
      "\u001b[32m[03/10 15:00:19 d2.data.common]: \u001b[0mSerialized dataset takes 2.49 MiB\n",
      "\u001b[32m[03/10 15:00:19 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=2\n",
      "\u001b[32m[03/10 15:00:19 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=2\n",
      "\u001b[32m[03/10 15:00:19 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...\n",
      "\u001b[32m[03/10 15:00:19 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...\n",
      "\u001b[32m[03/10 15:00:19 fvcore.common.checkpoint]: \u001b[0m[Checkpointer] Loading from /Users/giakhang/.torch/iopath_cache/detectron2/ImageNetPretrained/MSRA/R-50.pkl ...\n",
      "\u001b[32m[03/10 15:00:19 d2.checkpoint.c2_model_loading]: \u001b[0mRenaming Caffe2 weights ......\n",
      "\u001b[32m[03/10 15:00:19 d2.checkpoint.c2_model_loading]: \u001b[0mRenaming Caffe2 weights ......\n",
      "\u001b[32m[03/10 15:00:19 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with submodule backbone - Total num: 54\n",
      "\u001b[32m[03/10 15:00:19 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with submodule backbone - Total num: 54\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/10 15:00:19 fvcore.common.checkpoint]: \u001b[0mSome model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mhead.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mhead.bbox_subnet.0.{bias, weight}\u001b[0m\n",
      "\u001b[34mhead.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mhead.cls_subnet.0.{bias, weight}\u001b[0m\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/10 15:00:19 fvcore.common.checkpoint]: \u001b[0mThe checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mfc1000.{bias, weight}\u001b[0m\n",
      "  \u001b[35mstem.conv1.bias\u001b[0m\n",
      "\u001b[32m[03/10 15:00:19 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/10 15:00:19 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giakhang/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1708025539291/work/aten/src/ATen/native/TensorShape.cpp:3550.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/10 15:01:12 d2.utils.events]: \u001b[0m eta: 1 day, 22:22:56  iter: 19  total_loss: 3.916  loss_cls: 1.11  loss_box_reg: 2.713    time: 2.0693  last_time: 1.6450  data_time: 0.0843  last_data_time: 0.0110   lr: 0.00019981  \n",
      "\u001b[32m[03/10 15:01:12 d2.utils.events]: \u001b[0m eta: 1 day, 22:22:56  iter: 19  total_loss: 3.916  loss_cls: 1.11  loss_box_reg: 2.713    time: 2.0693  last_time: 1.6450  data_time: 0.0843  last_data_time: 0.0110   lr: 0.00019981  \n",
      "\u001b[32m[03/10 15:01:25 d2.engine.hooks]: \u001b[0mOverall training speed: 25 iterations in 0:00:49 (1.9984 s / it)\n",
      "\u001b[32m[03/10 15:01:25 d2.engine.hooks]: \u001b[0mOverall training speed: 25 iterations in 0:00:49 (1.9984 s / it)\n",
      "\u001b[32m[03/10 15:01:25 d2.engine.hooks]: \u001b[0mTotal training time: 0:00:50 (0:00:00 on hooks)\n",
      "\u001b[32m[03/10 15:01:25 d2.engine.hooks]: \u001b[0mTotal training time: 0:00:50 (0:00:00 on hooks)\n",
      "\u001b[32m[03/10 15:01:25 d2.utils.events]: \u001b[0m eta: 1 day, 21:47:41  iter: 27  total_loss: 3.916  loss_cls: 1.204  loss_box_reg: 2.713    time: 1.9798  last_time: 1.7603  data_time: 0.0026  last_data_time: 0.0020   lr: 0.00026974  \n",
      "\u001b[32m[03/10 15:01:25 d2.utils.events]: \u001b[0m eta: 1 day, 21:47:41  iter: 27  total_loss: 3.916  loss_cls: 1.204  loss_box_reg: 2.713    time: 1.9798  last_time: 1.7603  data_time: 0.0026  last_data_time: 0.0020   lr: 0.00026974  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazyconfig_train_net\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m do_train\n\u001b[0;32m----> 3\u001b[0m \u001b[43mdo_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/work/sand_box/hope_to_public_net/detectron2/tools/lazyconfig_train_net.py:108\u001b[0m, in \u001b[0;36mdo_train\u001b[0;34m(args, cfg)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m     start_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 108\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/engine/train_loop.py:155\u001b[0m, in \u001b[0;36mTrainerBase.train\u001b[0;34m(self, start_iter, max_iter)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_iter, max_iter):\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbefore_step()\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter_step()\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# self.iter == max_iter can be used by `after_train` to\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# tell whether the training successfully finished or failed\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# due to exceptions.\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/engine/train_loop.py:310\u001b[0m, in \u001b[0;36mSimpleTrainer.run_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    307\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;124;03mIf you want to do something with the losses, you can wrap the model.\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m loss_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loss_dict, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    312\u001b[0m     losses \u001b[38;5;241m=\u001b[39m loss_dict\n",
      "File \u001b[0;32m~/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/modeling/meta_arch/dense_detector.py:104\u001b[0m, in \u001b[0;36mDenseDetector.forward\u001b[0;34m(self, batched_inputs)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstances\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m batched_inputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstance annotations are missing in training!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    103\u001b[0m     gt_instances \u001b[38;5;241m=\u001b[39m [x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstances\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m batched_inputs]\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_instances\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    106\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_inference(images, features, predictions)\n",
      "File \u001b[0;32m~/dev/work/sand_box/hope_to_public_net/khang_net/modeling/meta_arch/yolof.py:79\u001b[0m, in \u001b[0;36mYOLOF.forward_training\u001b[0;34m(self, images, features, predictions, gt_instances)\u001b[0m\n\u001b[1;32m     75\u001b[0m pred_logits, pred_anchor_deltas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transpose_dense_predictions(\n\u001b[1;32m     76\u001b[0m     predictions, [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes, \u001b[38;5;241m4\u001b[39m]\n\u001b[1;32m     77\u001b[0m )\n\u001b[1;32m     78\u001b[0m anchors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manchor_generator(features)\n\u001b[0;32m---> 79\u001b[0m gt_labels, gt_boxes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_anchors\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_instances\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlosses(anchors, pred_logits, gt_labels, \n\u001b[1;32m     82\u001b[0m                    pred_anchor_deltas, gt_boxes)\n",
      "File \u001b[0;32m~/miniconda3/envs/hope_to_public_net/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/work/sand_box/hope_to_public_net/khang_net/modeling/meta_arch/yolof.py:167\u001b[0m, in \u001b[0;36mYOLOF.label_anchors\u001b[0;34m(self, anchors, gt_instances)\u001b[0m\n\u001b[1;32m    165\u001b[0m gt_labels, matched_gt_boxes \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m gt_per_image \u001b[38;5;129;01min\u001b[39;00m gt_instances:\n\u001b[0;32m--> 167\u001b[0m     match_quality_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mpairwise_iou\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgt_per_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgt_boxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manchors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m     matched_idxs, anchor_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manchor_matcher(match_quality_matrix)\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m match_quality_matrix\n",
      "File \u001b[0;32m~/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/structures/boxes.py:348\u001b[0m, in \u001b[0;36mpairwise_iou\u001b[0;34m(boxes1, boxes2)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpairwise_iou\u001b[39m(boxes1: Boxes, boxes2: Boxes) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    337\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;124;03m    Given two lists of boxes of size N and M, compute the IoU\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;124;03m    (intersection over union) between **all** N x M pairs of boxes.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03m        Tensor: IoU, sized [N,M].\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 348\u001b[0m     area1 \u001b[38;5;241m=\u001b[39m \u001b[43mboxes1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marea\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [N]\u001b[39;00m\n\u001b[1;32m    349\u001b[0m     area2 \u001b[38;5;241m=\u001b[39m boxes2\u001b[38;5;241m.\u001b[39marea()  \u001b[38;5;66;03m# [M]\u001b[39;00m\n\u001b[1;32m    350\u001b[0m     inter_area \u001b[38;5;241m=\u001b[39m pairwise_intersection(boxes1, boxes2)\n",
      "File \u001b[0;32m~/dev/work/sand_box/hope_to_public_net/detectron2/detectron2/structures/boxes.py:180\u001b[0m, in \u001b[0;36mBoxes.area\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03mComputes the area of all the boxes.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \n\u001b[1;32m    176\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;124;03m    torch.Tensor: a vector with areas of each box.\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    179\u001b[0m box \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensor\n\u001b[0;32m--> 180\u001b[0m area \u001b[38;5;241m=\u001b[39m (\u001b[43mbox\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m) \u001b[38;5;241m*\u001b[39m (box[:, \u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m-\u001b[39m box[:, \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m area\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tools.lazyconfig_train_net import do_train\n",
    "\n",
    "do_train(args, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d590de30-a2e9-46b6-81ec-90cbe406dd7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
